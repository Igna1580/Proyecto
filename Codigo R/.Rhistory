# 3a.1.5 Resultados importantes para la presente investigación
# -- La correlación más alta entre el consumo de alcohol y las variables del WHR, es la de apoyo social.
# -- La segunda correlación más alta entre consumo de alcohol y las variables es el índice de felicidad.
# -- Sabiendo que la correlación más alta de la matriz de correlación fue la de apoyo social con índice de felicidad, parece que estas tres variables están relacionadas.
# -- Parece una correlación muy débil y negativa entre el consumo de alcohol y las variables de generosidad y percepción de corrupción
# -- Va ser interesante evaluar la correlción entre consumo de alcohol y apoyo social.
# 3a.2 Cuadro 5: Correlación entre consumo de alcohol y variables de el índice de felicidad para cada región
# - Queremos ver si dividiendo los países por regiones, encontramos alguna correlación interesante entre el consumo de alcohol y las variables del WHR
# 3a.2.1 Regiones de interés
regiones_unicas <- c("Europa", "Africa Sub-sahariana", "Asia", "Australia y Oceania", "Norteamerica", "Suramerica", "Centroamerica y el Caribe", "Medio Oriente, Norte de Africa y Gran Arabia")
# 3a.2.2 Calcular la correlación de Spearman para cada región
correlaciones_Regiones <- data.frame(Variable = variables_interes)
for (region in regiones_unicas) {
subset_data <- base_datos[base_datos$Region == region, variables_interes]
correlaciones <- sapply(variables_interes, function(variable) cor(subset_data$poblacion_Total_consumo, subset_data[[variable]], method = "spearman"))
correlaciones_Regiones[region] <- correlaciones}
# 3a.2.3 Convertir las correlaciones a tipo numérico
correlaciones_Regiones[, -1] <- lapply(correlaciones_Regiones[, -1], as.numeric)
# 3a.2.4 Redondear los datos a dos decimales
correlaciones_Regiones[, -1] <- round(correlaciones_Regiones[, -1], 2)
print(correlaciones_Regiones)
# 3a.2.5 Resultados interesantes
# -- Europa: La correlación más significativa entre consumo de alcohol de la población total y las variables del WHR es negativa y es generosidad con una correlación débil de -0.30.
#           Es decir, parece ser a medida que aumenta el consumo de alcohol, la generosidad en esta región es menor.
# -- Africa Sub-sahariana: En esta región, la correlación más significativa entre el consumo de alcohol y las variables es la de apoyo social. La relación es positiva y de 0.43.
#                         Entonces en esta región, en cierto grado, a medida que aumenta el consumo de alcohol, aumenta también el apoyo social.
# -- Asia: En este país, las correlaciones entre consumo de alcoholy las variables del WHR están débiles, siendo la más significativa la de generosidad con -0.29.
# -- Australia y Oceanía: En esta región, sólo están dos países, sin embargo podemos decir que los dos países muestran el mismo comportamiento entre consumo de alcohol y las demás variables.
#                        En particular, las variables con correlación positiva son el de índice de felicidad y apoyo social.
# -- Norteamérica: En esta región, las variables de apoyo social, índice de felicidad, esperanza de vida saludable y generosidad tienen una correlación positiva de 0.5.
# -- Suramérica: En esta región, la correlación más significativa entre consumo de alcohol y las variables es el índice de felicidad con 0.73, seguida por apoyo social con 0.58.
# -- Centroamérica y el Caribe: En esta región, la relación más significativa entre consumo de alcohol y las demás variables es generosidad con -0.57.
#                              Por su parte, la segunda relación más significativa es la de apoyo social con 0.52.
# -- Medio Oriente, Norte de Africa y Gran Arabia: Para esta región, la correlación más significativa se da para la variable de esperanza de vida saldable con 0.77.
# - Entonces vemos como si analizamos por regiones, se evidencian diferentes correlaciones significativas.
# - Importante señalar que para ciertas regiones, se da una correlación negativa débil entre consumo de alcohol y generosidad.
# 3a.3 Cuadro 6: Correlación entre consumo de alcohol y variables de índice de felicidad para cada decil
# - También queremos ver la correlación entre consumo de alcohol y las demás variables del wHR, para ver si hay patrones diferentes si consideramos diferentes niveles de consumo de alcohol.
# 3a.3.1 Calcular las correlaciones para cada decil
correlaciones_Deciles <- data.frame(Variable = variables_interes)
deciles <- unique(base_datos2$decil_alcohol)
for (decil in deciles) {
subset_data <- base_datos2[base_datos2$decil_alcohol == decil, variables_interes]
correlaciones <- sapply(variables_interes, function(variable) {
cor(subset_data$poblacion_Total_consumo, subset_data[[variable]], method = "spearman")
})
correlaciones_Deciles[, as.character(decil)] <- correlaciones
}
print(correlaciones_Deciles)
# 3a.3.2 Resultados interesantes
# -- Deciles 1, 2, 4: Para estos deciles, la correlación más significativa entre consumo de alcohol y las variables del WHR es Percepción a la corrupción.
#                     Para decil 1 es de 0.277,  para decil 2 es de 0.505, para decil 3 es de -0.53.
#                     Note que en el caso de decil 1 y 2. lo que podemos interpretar es que a medida que se consideran consumo de alcohol más altos, la percepción de corrupción de los habitantes de estos países, también aumenta.
# -- Decil 3: En el caso de este decil, la correlación más signficativa es negativa, por -0.52747253 y correspondiente a la variable de esperanza de vida saludable.
#             Es decir, a medida de que aumenta el consumo de alcohol para este decil, la esperanza de vida saludable disminuye.
# -- Decil 5: En este caso, la correlación más significativa corresponde al índice de felicidad y es de -0.3351648.
# -- Decil 6 y 7: Contrario a lo visto en el decil 5, la correlación más significativa para estos dos deciles también corresponde al índice de felicidad pero esta vez positiva, de 0.73 y 0.65 respectivamente.
# -- Decil 8: Este decil que es el que vimos que tenía el índice de felicidad más alto, tiene la correlación más significativa de percepción a la corrupción y es negativa -0.49586965.
# -- Decil 9: La variable con la correlación más significativa es apoyo social y es de -0.40165100. Entonces a medida de que aumenta el consumo de alcohol, disminuye el apoyo social.
# -- Decil 10: Este decil que es el que consume más alcohol, muestra una no correlación para el índice de felcidad y percepción de la corrupción.
# - Vemos entonces que todos los deciles tienen comportamientos diferentes en relación a la correlación entre consumo de alcohol y las variables del WHR.
# - Los resultados del decil 8 son consistentes a lo que habíamos analizado pues este siendo el que vimos que tenia el índice de felcidad promedio más alto, también muestra que a medida de que aumenta el consumo de alcohol, parece ser que los habitantes consideran su país menos corrupto.
# 3b. Construir la función de distribución del coeficiente de correlación.
# - Queremos contruir la distribución del coeficiente de correlación de Spearman, lo cual lo haremos utilizando el método de Bootstrap.
# - Para ello, utilizamos la función boot, la cual considera la muestra original como la verdadera.
# - Nuestra muestra original tiene 131 datos, para los cuales tenemos datos de consumo de alcohol y el índice de felicidad, entonces la función lo que hace es agarrar 131 pares de datos aleatoriamente de la muestra original, los pares pueden repetirse y hace una muestra nueva de 131 datos.
# - A esa muestra nueva, le calcula el coeficiente de correlación de spearman, y lo almacena en un vector.
# - Este proceso lo repite 1000 veces y al final utilizamos ese vector para observar a la distribución del coeficiente de correlación.
set.seed(123) # para que toda las veces que lo corramos obtengamos el mismo boot
bootstrap_distribución_coeficiente <- boot(base_datos[c("poblacion_Total_consumo","indice_de_felicidad")], statistic = function(data, i) {
cor(data[i, "poblacion_Total_consumo"], data[i, "indice_de_felicidad"], method='spearman')}, R = 1000)
# 3b.1 Para visualizar los 1000 coeficientes de correlación
bootstrap_distribución_coeficiente$t
# 3b.2 Creamos un histograma de las muestras bootstrap
dist.coef.correlacion.spear <-   hist(bootstrap_distribución_coeficiente$t, main = "Distribución Bootstrap del coeficiente de correlación de Spearman",
xlab = "Coeficiente de correlación de spearman", col = "lightblue")
# 3b.3 Realizamos pruebas de hipotesis de normalidad
# - Nos interesa saber si nuestra distribución del coeficiente de correlación sigue una distribución normal
# - Hipotesis nula (H0): Los datos de la distribución del coeficiente de correlación de Spearman por metodo bootstrap siguen una distribución normal
# - Hipotesis alternativa (H1): Los datos de la distribución del coeficiente de correlación de Spearman por metodo bootstrap NO siguen una distribución normal
# 3b.3.1 Prueba de Kolmogrov-Smirnov
ks_test_coeficiente <- ks.test(
bootstrap_distribución_coeficiente$t,  # Los datos que se están probando
"pnorm",                        # La distribución teórica con la cual estamos comparando que en este caso, una distribución normal estándar
mean = mean(bootstrap_distribución_coeficiente$t),  # La media  de los datos de la correlación
sd = sd(bootstrap_distribución_coeficiente$t))
# - Resultados
# -- p-value = 0.7079
# -- D = 0.022199
# -- alternative hypothesis: two-sided
# -- p > 0.05 => No tenemos suficiente evidencia para rechazar la hipotesis nula, es decir , los resultados de la prueba de Kolmogrov-Smirnov no sugieren que los datos del coeficiente de correlación de spearman sean significativamente diferentes de una distribución normal.
# 3b.3.2 Prueba de Anderson-Darling
ad_test_coeficiente <- ad.test(bootstrap_distribución_coeficiente$t)
# - Resultados
# -- p-value = 0.1579
# -- A = 0.54828
# -- p > 0.05 => No tenemos suficiente evidencia para rechazar la hipotesis nula, es decir , los resultados de la prueba de Anderson Darling no sugieren que los datos del coeficiente de correlación de spearman sean significativamente diferentes de una distribución normal.
# 3b.3.3 Prueba de Lilliefors
lil_test_felicidad <- lillie.test(bootstrap_distribución_coeficiente$t)
# -- p-value = 0.2714
# -- D = 0.022199
# -- p > 0.05 => No tenemos suficiente evidencia para rechazar la hipotesis nula, es decir , los resultados de la prueba de Lilliefors no sugieren que los datos del coeficiente de correlación de spearman sean significativamente diferentes de una distribución normal.
# 3b.4 Conclusión general
# - No tenemos suficiente evidencia para rechazar la hipotesis nula.
# 3b.5 Calcular los estadísticos relevantes de la distribución del coeficiente de correlación de Spearman
minimo_dist <- round(min(bootstrap_distribución_coeficiente$t),2)
maximo_dist <- round(max(bootstrap_distribución_coeficiente$t),2)
rango_dist <- round(maximo_dist - minimo_dist,2)
media_dist <- round(mean(bootstrap_distribución_coeficiente$t),2)
mediana_dist <- round(median(bootstrap_distribución_coeficiente$t),2)
primer_cuartil_dist <- round(quantile(bootstrap_distribución_coeficiente$t, 0.25),2)
tercer_cuartil_dist <- round(quantile(bootstrap_distribución_coeficiente$t, 0.75),2)
rango_intercuartil_dist <- round(tercer_cuartil_dist - primer_cuartil_dist,2)
desviacion_estandar_dist <- round(sd(bootstrap_distribución_coeficiente$t),2)
varianza_dist <- round(var(bootstrap_distribución_coeficiente$t),2)
coeficiente_variacion_dist <- round(desviacion_estandar_dist / media_dist,2)
# 3b.5.1 Creamos un data frame con los resultados
resultados_estadisticos_dist <- data.frame(
Mínimo = minimo_dist,
Máximo = maximo_dist,
Rango = rango_dist,
Media = media_dist,
Mediana = mediana_dist,
PrimerCuartil = primer_cuartil_dist,
TercerCuartil = tercer_cuartil_dist,
RangoIntercuartil = rango_intercuartil_dist,
DesviacionEstandar = desviacion_estandar_dist,
Varianza = varianza_dist,
CoeficienteVariacion = coeficiente_variacion_dist
)
rownames(resultados_estadisticos_dist) <- "Distribución del coeficiente de correlación de Spearman"
print(resultados_estadisticos_dist)
# 3b.2 Resultados interesantes:
# -- La media de la distribución del coeficiente de correlación de Spearman entre el índice de felicidad y el consumo de alcohol es de 0.55.
# -- Originalmente, el coeficiente de correlación de spearman nos había dado exactamente igual, 0.55.
# -- El valor mínimo es de 0.34 y el máximo es 0.75.
# -- La varianza es cercana a 0.
# 3b. Objetivo: Determinar intervalos de confianza para la distribución del coeficiente de correlación.
# - Para cumplir con este objetivo específico, vamos a utilizar dos métodos para encontrar los intervalos de confianza
# 3b.1 Intervalos de confianza para el método bootstrap
# - Calcular los intervalos de confianza nos permite determinar que tan acertados son los resultados obtenidos.
# 3b.1.1 Calculamos la desviación estándar de los coeficientes de correlación de Spearman
sd_boot_spearman <- sd(bootstrap_distribución_coeficiente$t)
# 3b.1.2 Almacenamos la correlación entre consumo de alcohol y el índice de felicidad
r <- cor(base_datos2$poblacion_Total_consumo, base_datos2$indice_de_felicidad, method = "spearman")
# 3b.1.3 Para un nivel de confianza del 95%, buscamos el valor que deja un 2.5% de probabilidad en la cola derecha de una distribución normal est.
z <- qnorm(0.975)
# 3b.1.3 Calculamos los intervalos de confianza para el método de bootstrap
lower_bootstrap <- r - z * sd_boot_spearman
# -- Intervalo de confianza inferior = 0.4260598
upper_bootstrap <- r + z * sd_boot_spearman
# -- Intervalo de confianza superior = 0.6785526
# -- Interpretación: El intervalo [0.4260598, 0.6785526] contiente el coeficiente
#    de correlación de spearman entre el consumo de alcohol y el índice de feli-
#    cidad con un nivel de confianza del 95%.
# 3b.1.4 Queremos visualizar la densidad de la distribución del coeficiente de correlación bajo el método bootstrap con los intervalos de confianza
plot_densidad <- density(bootstrap_distribución_coeficiente$t)
# - Para guardarlo, abre el dispositivo de salida PDF
# pdf("grafico_distribucion_spearman.pdf", width = 8, height = 6)
plot(plot_densidad, main = "",
xlab = "Coeficiente de Correlación de Spearman", ylab = "Densidad", col = "blue") +
polygon(c(lower_bootstrap, plot_densidad$x, upper_bootstrap),
c(0, plot_densidad$y, 0), col = "lightblue") +
abline(v = c(lower_bootstrap, upper_bootstrap), col = "red", lwd = 2, lty = 2) +
abline(v = media_dist, col = "black", lwd = 1) +
text(lower_bootstrap, 0.005, "Límite Inferior = 0.43", srt = 90, adj = c(-0.5, -0.5)) +
text(upper_bootstrap, 0.005, "Límite Superior = 0.69", srt = 90, adj = c(-0.5, -0.5)) +
text(media_dist, 0.005, "Media = 0.55", srt = 90, adj = c(-0.3, -0.5), col = "black") +
cowplot::theme_cowplot()
# Cierra el dispositivo de salida PDF
# dev.off()
# 3b.2 Intervalos de confianza método delta, ajustado a spearman
# - Como nuestros datos de consumo de alcohol no son normales, no podemos utilizar el método delta para calcular los intervalos de confianza.
# - Sin embargo, utilizando lo establecido por Bonnett (2000), le podemos hacer una modificación a este método para calcular los intervalos de confianza utilizando la correlación de spearman.
# 3b.2.1 Función inversa de la tangente hiperbólica de la correlación entre consumo de alcohol y el índice de felicidad
# - trabajamos inicialmente en la escala arctan
d <- atanh(r)
# 3b.2.2 Varianza ajustada de los coeficientes de correlación de Spearman
var_d <- (1+(r^2)/2)/(nrow(base_datos)-3)
# 3b.2.3 Intervalos de confianza inferior y superior, regresamos a la escala original
lower_delta <- tanh(d - z*sqrt(var_d))
# -- lower_delta = 0.4100848
upper_delta <- tanh(d + z*sqrt(var_d))
# -- upper_delta <- 0.6683053
# 3b.2.3 Interpretación
# -- Utilizando el método delta ajustado para el coeficiente de correlación de spearman,
#    decimos que con una confianza del 95%, el coeficiente de correlación de spearman,
#    está en el intervalo [0.4100848, 0.6683053]
# 3c.Diferencias entre los intervalos de confianza
dif_inferior <- abs(lower_bootstrap-lower_delta)
# dif_inferor <- 0.01597501
dif_superior <- abs(upper_bootstrap-upper_delta)
# dif_superior <- 0.0102473
# 3c.1 Interpretación:
# -- Vemos que utilizando ambos métodos para calcular los intervalos de confianza,
#    los resultados fueron muy similares, con diferencias cerca de 0.01 para cada intervalo.
# -- Entonces, con una confianza del 95%, podemos decir que el coeficiente de correlación de Spearman
#    entre consumo de alcohol y el índice de felicidad está en el intervalo [0.43,0.69]
# -- En relación a nuestro proyecto de investigación, entonces lo que estamos observando es que sí existe
#    una correlación positiva entre el consumo de alcohol y el índice de felicidad en países alrededor del mundo.
# -- Estamos viendo que esa correlación, según la clasificación de Barrera (2014), se considera positiva media ó considerable.
# 4. Prueba de hipotesis
# Definir una función para dividir las correlaciones en S0 y S1
dividir_correlaciones <- function(correlaciones, umbral = 0.5, nivel_significancia = 0.05) {
S0 <- vector("list", length(correlaciones))
S1 <- vector("list", length(correlaciones))
for (i in 1:length(correlaciones)) {
p_valor <- cor.test(x = base_datos$poblacion_Total_consumo, y = base_datos$indice_de_felicidad, method = "spearman", exact = FALSE, conf.level = 0.95, conf.int = TRUE,
alternative = "two.sided")$p.value
if (p_valor >= nivel_significancia) {
S0[[i]] <- correlaciones[i]
} else {
S1[[i]] <- correlaciones[i]
}
}
S0 <- unlist(S0, use.names = FALSE)
S1 <- unlist(S1, use.names = FALSE)
return(list(S0 = S0, S1 = S1))
}
resultados <- dividir_correlaciones(bootstrap_distribucion_coeficiente$t, umbral = 0.5, nivel_significancia = 0.05)
resultados <- dividir_correlaciones(bootstrap_distribución_coeficiente$t, umbral = 0.5, nivel_significancia = 0.05)
resultados
# Definir una función para dividir las correlaciones en S0 y S1
dividir_correlaciones <- function(correlaciones, umbral = 0.5) {
S0 <- vector("list", length(correlaciones))
S1 <- vector("list", length(correlaciones))
for (i in 1:length(correlaciones)) {
if (correlaciones[i] >= umbral) {
S0[[i]] <- correlaciones[i]
} else {
S1[[i]] <- correlaciones[i]
}
}
S0 <- unlist(S0, use.names = FALSE)
S1 <- unlist(S1, use.names = FALSE)
return(list(S0 = S0, S1 = S1))
}
resultados <- dividir_correlaciones(bootstrap_distribución_coeficiente$t, umbral = 0.5, nivel_significancia = 0.05)
resultados <- dividir_correlaciones(bootstrap_distribución_coeficiente$t, umbral = 0.5)
resultados
length(resultados$S0)
length(resultados$S1)
x_bar_1 <- mean(bootstrap_distribución_coeficiente$t)
s_1 <- sd(bootstrap_distribución_coeficiente$t)
n <- length(bootstrap_distribución_coeficiente$t)
(u_1 <- sqrt(n) * (x_bar_1 - 4) / s_1)
x_bar_1 <- mean(bootstrap_distribución_coeficiente$t)
s_1 <- sd(bootstrap_distribución_coeficiente$t)
n <- length(bootstrap_distribución_coeficiente$t)
(u_1 <- sqrt(n) * (x_bar_1 - 0.5) / s_1)
x_bar_1
# Definir una función para dividir las correlaciones en S0 y S1
dividir_correlaciones <- function(correlaciones, correlacion0 = 0.5, c = 0.05) {
S0 <- vector("list", length(correlaciones))
S1 <- vector("list", length(correlaciones))
for (i in 1:length(correlaciones)) {
if (abs(correlaciones[i] - correlacion0) <= c) {
S0[[i]] <- correlaciones[i]
} else {
S1[[i]] <- correlaciones[i]
}
}
S0 <- unlist(S0, use.names = FALSE)
S1 <- unlist(S1, use.names = FALSE)
return(list(S0 = S0, S1 = S1))
}
resultados <- dividir_correlaciones(bootstrap_distribución_coeficiente$t, umbral = 0.5)
resultados <- dividir_correlaciones(bootstrap_distribución_coeficiente$t, correlacion0 = 0.5, c = 0.05)
resultados
# Definir una función para dividir las correlaciones en S0 y S1
dividir_correlaciones <- function(correlaciones, correlacion_media = mean(bootstrap_distribución_coeficiente$t), c = 0.05) {
S0 <- vector("list", length(correlaciones))
S1 <- vector("list", length(correlaciones))
for (i in 1:length(correlaciones)) {
if (abs(correlaciones[i] - correlacion0) <= c) {
S0[[i]] <- correlaciones[i]
} else {
S1[[i]] <- correlaciones[i]
}
}
S0 <- unlist(S0, use.names = FALSE)
S1 <- unlist(S1, use.names = FALSE)
return(list(S0 = S0, S1 = S1))
}
resultados <- dividir_correlaciones(bootstrap_distribución_coeficiente$t, correlacion_media, c = 0.05)
# Definir una función para dividir las correlaciones en S0 y S1
dividir_correlaciones <- function(correlaciones, correlacion_media = mean(bootstrap_distribución_coeficiente$t), c = 0.05) {
S0 <- vector("list", length(correlaciones))
S1 <- vector("list", length(correlaciones))
for (i in 1:length(correlaciones)) {
if (abs(correlaciones[i] - correlacion_media) <= c) {
S0[[i]] <- correlaciones[i]
} else {
S1[[i]] <- correlaciones[i]
}
}
S0 <- unlist(S0, use.names = FALSE)
S1 <- unlist(S1, use.names = FALSE)
return(list(S0 = S0, S1 = S1))
}
resultados <- dividir_correlaciones(bootstrap_distribución_coeficiente$t, correlacion_media, c = 0.05)
resultados <- dividir_correlaciones(bootstrap_distribución_coeficiente$t,mean(bootstrap_distribución_coeficiente$t), c = 0.05)
resultados
length(S0)
length(resultados$S0)
length(resultados$S1)
probabilidad_S1 <- length(resultados$S1) / length(bootstrap_distribución_coeficiente$t)
probabilidad_S1
probabilidad_S0 <- length(resultados$S0) / length(bootstrap_distribución_coeficiente$t)
probabilidad_S0
library(tidyverse)
library(janitor)
library(dplyr)
library(ggplot2)
library(plotly)
library(readxl)
library("papaja")
#abrir datos demograficos
Hombres_2023_demografia <- read_excel("repoblacev2011-2050-05_2.xlsx", sheet = "Cuadro 5 ", range = "G1017:G1177")
Mujeres_2023_demografia <- read_excel("repoblacev2011-2050-05_2.xlsx", sheet = "Cuadro 5 ", range = "G1857:G2017")
colnames(Hombres_2023_demografia) <- c("pob_H")
colnames(Mujeres_2023_demografia) <- c("pob_M")
#filtrar los datos demograficos
filtro <- c()
for (i in 0:19){
filtro <- c(filtro, (4+i*8):(8+i*8))
}
Hombres_2023_demografia <- Hombres_2023_demografia[filtro,1]
Mujeres_2023_demografia <- Mujeres_2023_demografia[filtro,1]
#abrir datos de probabilidades de transicion
Prob_Trans_Hombres <- read.csv("ProbTransHombres.csv", sep = ";")
Prob_Trans_Mujeres <- read.csv("ProbTransMujeres.csv", sep = ";")
#ajustarlas para que sumen 1
for(fila in 1:nrow(Prob_Trans_Hombres)){
for(col in 3:8){
Prob_Trans_Hombres[fila,col] <- Prob_Trans_Hombres[fila,col]/sum(Prob_Trans_Hombres[fila,3:8])
Prob_Trans_Mujeres[fila,col] <- Prob_Trans_Mujeres[fila,col]/sum(Prob_Trans_Mujeres[fila,3:8])
}
}
#--- Poblacion -----------------------------------------------------------------
edades <- 31:65
porcentajes <- c(0.05, 0.05, 0.08, 0.08, 0.10, 0.10, 0.15, 0.15, 0.20, 0.20, 0.25, 0.25, 0.30, 0.30, 0.35,
rep(0.6, 20))  # Luego, 20 porcentajes uniformes de 0.6
# Crear un dataframe para las edades
edades_df <- data.frame(Edad = edades-1)
edades_selec_H <- Hombres_2023_demografia[edades,]
# Unir el dataframe de edades con el dataframe de hombres
edades_selec_H <- cbind(edades_df, edades_selec_H)
# Luego puedes agregar este vector de porcentajes al dataframe edades_selec_H
edades_selec_H$porc_estimados <- porcentajes
# Calcular la población por edad (multiplicar la cantidad de hombres por el porcentaje)
edades_selec_H$pob_estimada<- edades_selec_H$pob_H* edades_selec_H$porc_estimados
# Caso Mujeres
edades_selec_M <- Mujeres_2023_demografia[edades,]
edades_selec_M <- cbind(edades_df, edades_selec_M)
edades_selec_M$porc_estimados <- porcentajes
edades_selec_M$pob_estimada<- edades_selec_M$pob_M * edades_selec_M$porc_estimados
# inflación en Costa Rica de los últimos 10 años según Base de datos del Fondo Monetario Internacional, Banco Mundial e indicador del IPC de la OCDE
inflacion_data <- data.frame(
Ano = c(2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022),
Costa_Rica = c(4.50, 5.23, 4.52, 0.80, -0.02, 1.63, 2.22, 2.10, 0.72, 1.73, 8.27)
)
inflacion <- mean(inflacion_data$Costa_Rica)
# descargamos la curva de rendimiento soberana de los últimos 6 meses
tasas_Descuento <- read_excel("descuento.xlsx")
descuento <- mean(tasas_Descuento$`3 meses`)
obtencion_tabla_proyeccion <- function(x,status,sexo) {
if (sexo == "H"){
probabilidades <- Prob_Trans_Hombres
}
if (sexo == "M"){
probabilidades <- Prob_Trans_Mujeres
}
tabla <- data.frame(
"edad" = x:111,
"l_age.x_sta.0" = rep(0, 112-x),
"l_age.x_sta.1" = rep(0, 112-x),
"l_age.x_sta.2" = rep(0, 112-x),
"l_age.x_sta.3" = rep(0, 112-x),
"l_age.x_sta.4" = rep(0, 112-x),
"l_age.x_sta.5" = rep(0, 112-x)
)
tabla[1,status+2] = 1
c(10000, rep(0, 111-x))
for (fila in 2:nrow(tabla)){
for (col in 2:7){
tabla[fila,col] <-
tabla[fila-1,2]*probabilidades[(fila+x-21),col+1] +
tabla[fila-1,3]*probabilidades[(fila+x-21)+91,col+1] +
tabla[fila-1,4]*probabilidades[(fila+x-21)+182,col+1] +
tabla[fila-1,5]*probabilidades[(fila+x-21)+273,col+1] +
tabla[fila-1,6]*probabilidades[(fila+x-21)+364,col+1] +
tabla[fila-1,7]*probabilidades[(fila+x-21)+455,col+1]
}
}
return (tabla)
}
#Función de probabilidad
tPx_ij <- function(t=1,x=65,i=0,j=0,sexo){
p <- obtencion_tabla_proyeccion(x,i,sexo)[t+1,j+2]
return(p)
}
#Función de anualidad prepagable
ax.n_ij <- function(x,n,i=0,j,r=5.8,inf=2.8818,sexo){
prob <- obtencion_tabla_proyeccion(x,i,sexo)
resultado <- 0
for (e in 0:(n-1)){
resultado <- ((1+inf/100)/(1+r/100))^(e)*prob[e+1,j+2] + resultado
}
return(resultado)
}
#Función anualidad diferida
ax.u_ij <- function(x, u=65-x, i=0, j, r=5.8, inf=2.8818, sexo){
diferida <- ax.n_ij(x, 110-x, i, j, r, inf, sexo) - ax.n_ij(x, u, i, j, r, inf, sexo)
return(diferida)
}
A <- 183671.1703 #Beneficio estado 1
B <- 363381.6771 #Beneficio estado 2
C <- 740398.8263 #Beneficio estado 3
D <- 1572738.998 #Beneficio estado 4
# Crear un vector vacío para almacenar los resultados de hombres
benef_H_indiv <- data.frame(benef_H_indiv = numeric())
for (x in 30:64) {
beneficios_por_edad_hombres <- (A*ax.u_ij(x,65-x,i=0,j=1,sexo="H")) +
(B*ax.u_ij(x, 65-x,i=0,j=2,sexo="H")) +
(C*ax.u_ij(x, 65-x,i=0,j=3,sexo="H")) +
(D*ax.u_ij(x, 65-x,i=0,j=4,sexo="H"))
benef_H_indiv <- rbind(benef_H_indiv, data.frame(benef_H_indiv = beneficios_por_edad_hombres))
}
edades_selec_H <- cbind(edades_selec_H, benef_H_indiv = benef_H_indiv)
colnames(edades_selec_H)[5] <- "Benef_ind_por_edad"
benef_tot_por_edad <- edades_selec_H[, 5] * edades_selec_H[, 4]
benef_tot_por_edad <- as.vector(benef_tot_por_edad)
edades_selec_H <- cbind(edades_selec_H, benef_tot_por_edad)
suma_benef_H_total <- sum(edades_selec_H$benef_tot_por_edad)
# Crear un vector vacío para almacenar los resultados de mujeres
benef_M_indiv <- data.frame(benef_M_indiv = numeric())
for (x in 30:64) {
beneficios_por_edad_mujeres <- (A*ax.u_ij(x, 65-x,i=0,j=1,sexo="M")) +
(B*ax.u_ij(x, 65-x,i=0,j=2,sexo="M")) +
(C*ax.u_ij(x, 65-x,i=0,j=3,sexo="M")) +
(D*ax.u_ij(x, 65-x,i=0,j=4,sexo="M"))
benef_M_indiv <- rbind(benef_M_indiv, data.frame(benef_M_indiv = beneficios_por_edad_mujeres))
}
edades_selec_M <- cbind(edades_selec_M, benef_M_indiv = benef_M_indiv)
colnames(edades_selec_M)[5] <- "Benef_ind_por_edad"
benef_tot_por_edad_M <- edades_selec_M[, 5] * edades_selec_M[, 4]
benef_tot_por_edad_M <- as.vector(benef_tot_por_edad_M)
edades_selec_M <- cbind(edades_selec_M, benef_tot_por_edad_M)
suma_benef_M_total <- sum(edades_selec_M$benef_tot_por_edad_M)
primas_hombres <- data.frame(Primas_hombres = numeric())
for (x in 30:64) {
primas_por_edad_hombres <- (ax.n_ij(x,n = 65-x,i=0,j=0,sexo="H")) +
(ax.n_ij(x,n = 65-x,i=0,j=1,sexo="H")) +
(ax.n_ij(x,n = 65-x,i=0,j=2,sexo="H"))
primas_hombres <- rbind(primas_hombres, data.frame(Primas_hombres = primas_por_edad_hombres))
}
edades_selec_H <- cbind(edades_selec_H, Primas_Hombres = primas_hombres)
colnames(edades_selec_H)[7] <- "primas_ind_por_edad "
primas_tot_por_edad <- edades_selec_H[, 7] * edades_selec_H[, 4]
primas_tot_por_edad <- as.vector(primas_tot_por_edad)
edades_selec_H <- cbind(edades_selec_H, primas_tot_por_edad)
primas_hombres_suma <- sum(edades_selec_H$primas_tot_por_edad)
# mujeres
primas_mujeres <- data.frame(Primas_mujeres = numeric())
for (x in 30:64) {
primas_por_edad_mujeres <- (ax.n_ij(x,n = 65-x,i=0,0,5.8,inf=2.8818,"M")) +
(ax.n_ij(x,n = 65-x,i=0,1,5.8,inf=2.8818,"M")) +
(ax.n_ij(x,n = 65-x,i=0,2,5.8,inf=2.8818,"M"))
primas_mujeres <- rbind(primas_mujeres, data.frame(Primas_mujeres = primas_por_edad_mujeres))
}
edades_selec_M <- cbind(edades_selec_M, Primas_Mujeres = primas_mujeres)
colnames(edades_selec_M)[7] <- "primas_ind_por_edad "
primas_tot_por_edad_M <- edades_selec_M[, 7] * edades_selec_M[, 4]
primas_tot_por_edad_M <- as.vector(primas_tot_por_edad_M)
edades_selec_M <- cbind(edades_selec_M, primas_tot_por_edad_M)
primas_mujeres_suma <- sum(edades_selec_M$primas_tot_por_edad_M)
beneficios_totales <- suma_benef_M_total + suma_benef_H_total
primas_0.95 <- (primas_hombres_suma + primas_mujeres_suma)*0.95
costo_inicial <- 0.15*(sum(edades_selec_H$pob_estimada)+sum(edades_selec_M$pob_estimada))
total_primas <- primas_0.95 - costo_inicial
prima_anual <- beneficios_totales / total_primas #P_anual = 205,600.47
prima_mensual <- prima_anual/12 #P_mensual = 17,133.37
#Hombres
primas_0.95_hombres <- primas_hombres_suma*0.95
total_primas_hombres <- primas_0.95_hombres - 0.15*sum(edades_selec_H$pob_estimada)
prima_hombres_anual <- suma_benef_H_total / total_primas_hombres #P_H_anual = 167,408.38
prima_hombres_mensual <- prima_hombres_anual/12 #P_H_mensual = 13,950.69
#Mujeres
primas_0.95_mujeres <- primas_mujeres_suma*0.95
total_primas_mujeres <- primas_0.95_mujeres - 0.15*sum(edades_selec_M$pob_estimada)
prima_mujeres_anual <- suma_benef_M_total / total_primas_mujeres #P_M_anual=243,169.13
prima_mujeres_mensual <- prima_mujeres_anual/12 #P_M_mensual = 20,264.09
Prima_justa_H <- edades_selec_H[,5]/(edades_selec_H[,7] - 0.15)
Prima_justa_H_mensual <- Prima_justa_H/12
edades_selec_H <- cbind(edades_selec_H, Prima_justa_anual = Prima_justa_H)
edades_selec_H <- cbind(edades_selec_H, Prima_justa_mensual = Prima_justa_H_mensual)
Prima_justa_M <- edades_selec_M[,5]/(edades_selec_M[,7] - 0.15)
Prima_justa_M_mensual <- Prima_justa_M/12
edades_selec_M <- cbind(edades_selec_M, Prima_justa_anual = Prima_justa_M)
edades_selec_M <- cbind(edades_selec_M, Prima_justa_mensual = Prima_justa_M_mensual)
p = ggplot() +
geom_line(data = edades_selec_H, aes(x = Edad, y = pob_estimada, color = "Hombres"), linetype = "solid", size = 1) +
geom_line(data = edades_selec_M, aes(x = Edad, y = pob_estimada, color = "Mujeres"), linetype = "solid", size = 1) +
scale_color_manual(values = c("Hombres" = "lightblue4", "Mujeres" = "maroon"), name = "Población") +
xlab('Edad') +
ylab('Población estimada') + cowplot::theme_cowplot()
print(p)
#abrir datos demograficos
Hombres_2023_demografia <- read_excel("repoblacev2011-2050-05_2.xlsx", sheet = "Cuadro 5 ", range = "G1017:G1177")
#abrir datos demograficos
Hombres_2023_demografia <- read_excel("repoblacev2011-2050-05_2.xlsx", sheet = "Cuadro 5 ", range = "G1017:G1177")
